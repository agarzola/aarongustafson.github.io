<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title><![CDATA[Aaron Gustafson - Latest Posts]]></title>
	<link href="http://aaron-gustafson.com/atom-latest-posts.xml" rel="self"/>
	<link href="http://aaron-gustafson.com/"/>
	<updated>2015-02-23T12:56:34-05:00</updated>
	<id>http://aaron-gustafson.com/</id>
	<author>
		<name><![CDATA[Aaron Gustafson]]></name>
		
	</author>
	<generator uri="http://octopress.org/">Octopress</generator>

	
		
			<entry>
				<title type="html"><![CDATA[Consider How Your Forms Read]]></title>
				<link href="http://aaron-gustafson.com/notebook/consider-how-your-forms-read/"/>
				<updated>2015-02-23T11:21:24-05:00</updated>
				<id>http://aaron-gustafson.com/notebook/consider-how-your-forms-read</id>
				<content type="html"><![CDATA[<p>While listening to <a href="http://www.radiolab.org/story/trust-engineers/">Radiolab’s &ldquo;The Trust Engineers&rdquo;</a>, I’ll admit I got a little excited when they started talking about web form performance. And no, not &ldquo;performance&rdquo; in the time-to-download sense, but &ldquo;performance&rdquo; in terms of how well the forms performed in attempting to capture meaningful, actionable data.</p>

<!-- more -->


<p>I’ll set the scene: It’s the holiday season in 2011 and people are uploading photos to Facebook like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>Anyway, one unintended consequence of this deluge of photo uploads was a significant uptick in <a href="https://www.facebook.com/help/189722821075378">photo reports</a>. Facebook received millions of them, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were miscategorized.</p>

<p>When Facebook engineers reached out to some of the users who had reported these photos for a bit more background behind their decisions, they discovered that many of the reports were because users didn’t want the photo on Facebook reasons other than the options provided. In some cases it was because they didn’t like how they looked in the photo and in others it was because the photo was of an ex or even a beloved pet they shared with an ex.</p>

<p>The existing photo reporting form had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
<li>Embarrassing</li>
<li>Upsetting</li>
<li>Saddening</li>
<li>Bad Photo</li>
<li>Other</li>
</ul>


<p>The &ldquo;other&rdquo; option also provided a free-response field to fill in.</p>

<p>With this system in place, they found that 50% of reporters would choose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the &ldquo;other&rdquo; respondents were writing &ldquo;It’s embarrassing&rdquo; in the blank rather than choosing the &ldquo;embarrassing&rdquo; option already provided.</p>

<p>What they realized was that people were not identifying with the &ldquo;embarrassing&rdquo; text (or may have even thought it was referring to them, rather than assuming the implied &ldquo;It’s&rdquo;). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em>. And they updated the options to mirror how people actually talk:</p>

<ul>
<li>It’s embarrassing</li>
<li>It’s a bad photo of me</li>
<li>It makes me sad</li>
</ul>


<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Sometimes we feel compelled to create forms that are very clinical. In the survey world we’re often taught to limit the &ldquo;personality&rdquo; of our forms in order to avoid influencing the responses.</p>

<p>That said, we need to remember that we are authoring interfaces that will be used by actual people. When we are creating forms that don’t require that kind of scientific rigor, we can (and should) do whatever we can to make the interaction more human.</p>

<p>Ask real questions: <em>What’s your name?</em>, <em>What’s your email?</em>, and <em>How would you prefer we contact you?</em> are far more friendly than <em>Name</em>, <em>Email</em>, and <em>Contact Preference</em>.</p>

<p>A little thoughtful consideration for the people who need to fill in your form goes a long way toward making them feel at ease and also helps to ensure the feedback you receive is accurate, valuable, and actionable.</p>
]]></content>
			</entry>
		
	
		
			<entry>
				<title type="html"><![CDATA[Who Should Pay?]]></title>
				<link href="http://aaron-gustafson.com/notebook/who-should-pay/"/>
				<updated>2015-02-18T23:35:06-05:00</updated>
				<id>http://aaron-gustafson.com/notebook/who-should-pay</id>
				<content type="html"><![CDATA[<p>In more than a handful of conversations lately, it’s become quite clear that we, the web development community, are prioritizing our own convenience and our own time over that of our users. With our industry’s focus on “user-centered design”, you might find that hard to believe, but it’s true.</p>

<!-- more -->


<p>Here’s one example. In reaction to <a href="http://aaron-gustafson.com/notebook/css-variables-are-a-bad-idea/">my post on why I think CSS variables are a bad idea</a>, <a href="http://sass-lang.com">SASS</a> core team member <a href="https://twitter.com/chriseppstein/">Chris Eppstein</a> had this to say:</p>

<div class='embed tweet'><blockquote class="twitter-tweet"><p><a href="https://twitter.com/AaronGustafson">@AaronGustafson</a> Authoring CSS shouldn’t be so onerous as to require the use of a preprocessor.</p>&mdash; Chris Eppstein (@chriseppstein) <a href="https://twitter.com/chriseppstein/status/567756897105620992">February 17, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div>


<p>Fundamentally, I agree with his sentiment: A preprocessor should <em>not</em> be a requirement for authoring CSS. Thankfully, <em>it never was</em>; you can build amazing things using only hand-authored CSS. And if you find a preprocessor helpful to your process for one reason or another, great. But using a preprocessor never has been (nor should it ever be) a requirement.</p>

<p>But Chris was not railing against preprocessors. Instead, he is echoing a sentiment held by many people in the preprocessor community. He feels CSS is not as powerful as it could/should be and he hopes that one day soon preprocessors won’t need to exist because CSS will have all of the features they offer natively. Like variables.</p>

<p>I used to feel that way. I used to want variables… and mixins… and functions… and loops… and declaration block-level inheritance. But I’ve changed my mind.</p>

<p>Don’t get me wrong, I love these constructs. I use them nearly every day in the SASS I write and I am incredibly thankful for the hard work that has gone into their creation and maintenance.  Chris alone has probably saved me several weeks worth of work over the last four years through his contributions to SASS and <a href="http://compass-style.org/">Compass</a>. I definitely owe him a beer (or three).</p>

<p>Ok, so if my issue is not with the idea of programmatically generating styles, why would I not want these to be part of CSS, the <i>lingua franca</i> for design on the Web? Well, it’s pretty simple: Converting all of these constructs into something that is actionable by the browser takes time and processing power. Someone has to pay that cost and I wouldn’t feel right passing that cost on to my end users if there are better options.</p>

<p>This is a topic I bring up often in my conference talks and workshops: Every decision we make affects the user experience in some way.</p>

<p>When we add another JavaScript library or plugin, it’s no big deal from our perspective. We tend to have fast connections and faster processors. For our users it’s another story: It’s one more thing to request. One more thing to download. One more script to parse. One more thing holding up page rendering. One more reason to leave our site and seek out a competitor who actually values their time.</p>

<p>When we hide an <code>img</code> in the small screen version of our responsive design using <code>display: none</code>, the cost to us is quite minimal. It’s just one little declaration. What’s the harm? But the cost to our end users is quite significant: Longer load times, slower performance, and (in some cases) in real dollars if they are on a <a href="http://blog.kaspersky.com/cost-aware/">metered data connection</a>. And they don’t even get to see the image they paid for!</p>

<p>When we decide to build a site using a front-end JavaScript MVC framework, it can make the development process go so much faster for us and we can reduce our need for a robust back-end infrastructure. I mean everyone has JavaScript these days… <a href="http://aaron-gustafson.com/notebook/a-fundamental-disconnect/">the browser is the new VM</a>. But when we do this, our users suffer because we don’t give their browsers real HTML. Instead we force them to download a hefty framework so we can move all of the processing we would normally handle on a much faster, dedicated server to their questionably-capable machine instead. Oh, and if the browser encounters an error while parsing or executing the JavaScript execution, they don’t get anything at all. Welcome to the Modern Web™!</p>

<hr>


<p>When I look around, I see our community spending a lot of time coming up with new tools and techniques to make our jobs easier. To ship faster. And it’s not that I’m against efficiency, but I think we need to consider the implications of our decisions. And if one of those implications is making our users suffer—or potentially suffer—in order to make our lives easier, I think we need to consider their needs above our own.</p>

<p>So yes, I would love a world where preprocessors are unnecessary, but I would much rather spend a few seconds (or even a few minutes) transcompiling my SASS into CSS in order to save my users even a few milliseconds. It’s the same reason I optimize my images, minify my JavaScript, use Gzip, and lazy load design and experience enhancements only in contexts where they provide a real benefit.</p>

<p>Our users should never foot the bill for our convenience. We need to put their needs above our own.</p>
]]></content>
			</entry>
		
	
		
			<entry>
				<title type="html"><![CDATA[I Don’t Want to Teach the World to Code… I Want to Teach the World to Problem Solve]]></title>
				<link href="http://aaron-gustafson.com/notebook/i-dont-want-to-teach-the-world-to-code/"/>
				<updated>2015-02-15T17:51:36-05:00</updated>
				<id>http://aaron-gustafson.com/notebook/i-dont-want-to-teach-the-world-to-code</id>
				<content type="html"><![CDATA[<p>It seems that every other day a new code school opens it doors. In my mid-sized city, Chattanooga, there are no fewer than three businesses centered around teaching “coding” classes<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> that I am aware of. And there are at least a half-dozen free or community driven programs and camps on top of that. Most are aimed at youth, but some offer adult education as well. And that, of course, is over and above what&rsquo;s available in our public and private schools (which is considerable) and a plethora of online options.</p>

<!-- more -->


<p>On one hand I think this is great. I love to code and I love to share my knowledge of that world with anyone who will listen (I’m sorry, Kelly). Also, as someone who ran a web design studio, I know first hand how hard it is to find talented people to hire. More coders equals a larger talent pool; it&rsquo;s simple math.</p>

<p>Currently—at least here in the U.S.—the numbers aren&rsquo;t where we need them to be. We just aren&rsquo;t graduating enough STEM (Science, Technology, Engineering, and Math) students. And the pressure to fill open positions has led to a lot of outsourcing and an increased demand for employment visas. As an unemployed or unhappy worker, making yourself employable as a coder sounds like a win-win.</p>

<p>Couple this with the constant barrage of news about startup acquisitions and funding rounds and it certainly seems like learning to code is your key to financial stability if not extreme wealth. (The “American Dream,” right?) But it’s not.</p>

<p>As Jerry Davis pointed out so deftly in the <cite>Harvard Business Review</cite>, <a href="http://blogs.hbr.org/2014/03/why-do-app-developers-still-live-with-their-moms/">the vast majority of startups don&rsquo;t succeed</a>. Learning to code is not a guarantee of wealth and success. And, let’s be honest, not everyone is wired for coding and that&rsquo;s okay.</p>

<p>So I’m not sure everyone needs to learn to code. That said, I think this movement (if you can call it that) has merit.</p>

<p>First off, on the Web side of things, I think learning to code can be empowering. The Web is for everyone and I love to see more and more people using it as a tool to amplify their voices and to build community across the globe. So for that reason alone I&rsquo;m thrilled these programs exist.</p>

<p>The other reason I like that people are learning to code is that it changes how they see and deal with problems.</p>

<p>As a programmer, I am forced to break lumbering, gnarly problems into simpler, accomplishable tasks. I&rsquo;m forced to think about cause and effect, of process, of the steps required to achieve the desired outcome.</p>

<p>I also experience failure. Constantly. I&rsquo;ve learned to find the errors in my own logic, to second guess myself, to refine and improve, to refactor my code and my brain. This constant refinement helps me achieve a deeper understanding of my tools and my medium.</p>

<p>To me, those lessons (taught to me through nearly 20 years of coding) are invaluable. These are the sorts of lessons I wish they taught in school, but sadly the U.S. has largely done away with reason and critical thinking in favor of memorization and regurgitation. So maybe it&rsquo;s something we need to learn at home. Or in a coding class.</p>

<p>Regardless, if the world was filled with curious people who asked questions, applied logic, and refined their understanding of the challenges they see every day, I can&rsquo;t help but think we would all be far better off.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>I should note that I am lumping a bunch of stuff into the umbrella of “coding” because some of these teach front-end web technologies, others teach those plus back-end stuff in PHP or Python, and others teach maker-style classes focused around robotics and DIY electronics like Arduino.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
			</entry>
		
	
		
			<entry>
				<title type="html"><![CDATA[Three Worthwhile Posts on Progressive Enhancement]]></title>
				<link href="http://aaron-gustafson.com/notebook/three-worthwhile-posts-on-progressive-enhancement/"/>
				<updated>2015-02-13T10:14:40-05:00</updated>
				<id>http://aaron-gustafson.com/notebook/three-worthwhile-posts-on-progressive-enhancement</id>
				<content type="html"><![CDATA[<p>Jason Garber has penned a series of posts on progressive enhancement. Here’s a quick rundown on what they cover and why you should read them.</p>

<!-- more -->


<h2><a href="http://sixtwothree.org/posts/designing-experience-layers">Designing Experience Layers</a></h2>

<p>In his first post, Jason picks up on a drumbeat I’ve been hammering on for years: we need to consider experience a continuum, not a monolithic thing.</p>

<blockquote><p>Today’s Web makes no guarantees. Every bit of code—HTML, CSS, and JavaScript—shipped from a server across the wire acts as a suggestion as to how the browser should interpret and display content. More often than not, everything works planned, but for any number of reasons, a browser could fail to request or render a particular asset.</p></blockquote>

<p>In other words, get to know <a href="http://adaptivewebdesign.info/1st-edition/chapter-1.html#adapt-or-die">fault tolerance as it applies to web design</a> and <a href="http://aaron-gustafson.com/notebook/a-fundamental-disconnect/">don’t make any assumptions about how your content will be rendered/experienced</a>.</p>

<p>His conclusion is an important one:</p>

<blockquote><p>Approaching design through the lens of experience layers is the design strategy for the Web; one that’s better for users and designers alike.</p></blockquote>

<p>Amen!</p>

<h2><a href="http://sixtwothree.org/posts/in-defense-of-progressive-enhancement">In Defense of Progressive Enhancement</a></h2>

<p>In his follow-up, Jason defends his position against <a href="http://viget.com/inspire/designing-experience-layers#comment-1847156038">a lengthy comment from his supervisor at Viget</a>. Jason’s responses are dead on:</p>

<ol>
<li>JavaScript is not a baseline (or a given) and</li>
<li>When large sites put their eggs in the JS basket, they set a bad example for other developers.</li>
</ol>


<p>His summation is perfect:</p>

<blockquote><p>I remain unconvinced that abandoning progressive enhancement in favor of JavaScript-first development is better for users or is the direction the Web is inevitably heading. It’s our responsibility to do right by the billions already online and the next billion preparing to come online. We can achieve this by designing robust, resilient, layered experiences using techniques like progressive enhancement.</p></blockquote>

<p>Again, fantastic.</p>

<h2><a href="http://sixtwothree.org/posts/the-practical-case-for-progressive-enhancement">The Practical Case for Progressive Enhancement</a></h2>

<p>Continuing the thread, Jason assembles more reasons to adopt the progressive enhancement philosophy.</p>

<ol>
<li><strong>The “Moral” Argument for Progressive Enhancement</strong> &ndash; Personally, I think Jason gives in too easily on this. Access to content is <a href="http://www.pewinternet.org/topics/digital-divide/">a social justice issue</a> and that is nothing to gloss over. In some cases it is also a <a href="http://www.section508.gov/">legal requirement</a>.</li>
<li><strong>The “Cost” of Progressive Enhancement</strong> &ndash; Jason does a good job addressing the costs (monetarily and temporally) associated with adopting progressive enhancement in terms of building, testing, and supporting websites. As he says, it is more costly to &ldquo;bolt on&rdquo; accessibility and progressive enhancement at the end of a project. He is also correct in his assertion that progressively-enhanced websites actually require less testing. And when you <a href="http://bradfrost.com/blog/mobile/support-vs-optimization/">draw a stark line between support and optimization</a>, support for additional browsers and devices also becomes far less costly. What Jason was missing was numbers to back all this up. <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement/">I have those numbers</a>. Enjoy.</li>
<li><strong>Practicality</strong> &ndash; Finally, Jason calls out games and their ilk as edge cases. He correctly asserts that the vast majority of properties on the Web could easily be built following progressive enhancement. Sure, you might not build a Photoshop clone using progressive enhancement, but how many of you are building an image editor for the Web? I didn’t think so.</li>
</ol>


<h2>Conclusion</h2>

<p>In all, this was a nice little series. Great work Jason! If you want to dig into this progressive enhancement stuff a bit more, you can read the entirety of my award-winning book <a href="http://adaptivewebdesign.info/1st-edition/"><cite>Adaptive Web Design: Crafting Rich Experiences with Progressive Enhancement</cite> online, for free</a>.</p>
]]></content>
			</entry>
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
</feed>
