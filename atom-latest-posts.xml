<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title><![CDATA[Aaron Gustafson - Latest Posts]]></title>
	<link href="https://www.aaron-gustafson.com/atom-latest-posts.xml" rel="self"/>
	<link href="https://www.aaron-gustafson.com/"/>
	<updated>2016-03-16T12:05:22-05:00</updated>
	<id>https://www.aaron-gustafson.com/</id>
	<author>
		<name><![CDATA[Aaron Gustafson]]></name>
		
	</author>
	<generator uri="http://octopress.org/">Octopress</generator>

	
		
			<entry>
				<title type="html"><![CDATA[An Event Apart Nashville 2016, Day One]]></title>
				<link href="https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one/"/>
				<updated>2016-03-16T09:54:59-05:00</updated>
				<id>https://www.aaron-gustafson.com/notebook/an-event-apart-nashville-2016-day-one</id>
				<content type="html"><![CDATA[<p>Unfortunately, I was unable to spend Tuesday in Nashville for An Event Apart (for reasons that will be revealed in about a month), but I did catch Monday and it was amazing.</p>

<!-- more -->

<p>The esteemed <a href="http://www.zeldman.com/">Jeffrey Zeldman</a> kicked the day off with a talk entitled <em>Designing with Web Standards in 2016</em>. A theme he touched on repeatedly was that none of the problems we are facing in web design today are new problems. It’s a topic near and dear to my heart, something I wrote about in the closing chapter of <a href="http://adaptivewebdesign.info/2nd-edition/"><cite>Adaptive Web Design’s</cite> Second Edition</a> and <a href="https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future/">recently spoke about at EnhanceConf in London</a>. He knocked this one out of the park and my head was nodding so much my neck began to hurt.</p>

<p>Next up was <a href="http://www.webstandards.org/about/members/">my former WaSP colleague</a> <a href="https://rachelandrew.co.uk/">Rachel Andrew</a> to give us the skinny on CSS Grid Layouts. This is an amazing spec that I’ve always struggled to understand fully (despite the fact that’s i’ve written a Javascript polyfill for it). Rachel made it crystal clear and got me very excited about the future of layout on the Web.</p>

<p><a href="http://jensimmons.com/">Jen Simmons</a> dropped some serious CSS-related design knowledge bombs that perfectly complimented Rachel’s talk. She discussed Flexbox, CSS Shapes, Multi-column layout, viewport units and more, demonstrating how they can be used right now to progressively enhance the design of your sites.</p>

<p>After lunch, <a href="http://bradfrost.com/">Brad Frost</a> took to the stage to talk about Style Guides. I only caught the last half—I’ll admit to doing some last-minute rehearsing in the hallway—but the bits I did catch were good. I’ve seen his Atomic Design talk a few times, which this one builds on. In this talk he touches on a lot of the atomic design concepts, but he also talked a lot more about workflow and the role of the front-end developer. No doubt the evolution of this talk has come in large part through writing <a href="http://atomicdesign.bradfrost.com/">a book on Atomic Design</a> and in hosting <a href="http://styleguides.io/podcast/">a podcast with Anna Debenham on website style guides</a>.</p>

<p>Next, I was given the opportunity to share some thoughts and advice on designing and building. My talk, <em>The Features of Highly Effective Forms</em>, evolved out of several earlier talks on building forms. With this one, I wanted to strike a little more balance between the nuts and bolts of building forms and the hows and whys of building better forms.</p>

<p>The deck, <a href="http://www.slideshare.net/AaronGustafson/the-features-of-highly-effective-forms-an-event-apart-nashville-2016">which I’ve posted to SlideShare</a>, doesn’t stand on its own quite as well as some of my other forms decks simply because the talk contained a lot of storytelling I chose not to pair with slides—instead opting for an black screen so folks could focus—but I did call out the salient points. I’ve begun writing up some of the recommendations as part of my <a href="https://www.aaron-gustafson.com/notebook/tags/web-forms/">Modern Web Forms Best Practices series</a> and will continue to do so in the future. And one of the stories I told, which I highly recommend you check out, had to do with <a href="https://www.aaron-gustafson.com/notebook/consider-how-your-forms-read/">a lesson Facebook learned in managing how users report offensive photos</a>.</p>

<p><a href="https://bigmedium.com/">Josh Clark</a> wrapped the day up with a discussion of the future of interface as things move from digital back to physical. He talked about a lot of really cool new tech that has me excited about the future, including <a href="https://google.github.io/physical-web/">the Physical Web</a>, which Josh had running as a live demo. I wonder if anyone noticed I had a beacon running too ;-)</p>

<p>All in all, day one was a blast. As always, Jeffrey, Eric, <a href="https://www.linkedin.com/in/toby-malina-6247a028">Toby</a>, and <a href="http://www.escapadeproductions.com/">Marci</a> do an awesome job programming their events. I’m really bummed I could not stick around to see <a href="http://valhead.com/">Val</a>, <a href="https://twitter.com/grigs">Jason</a>, <a href="http://www.kryshiggins.com/">Krystal</a>, <a href="http://meyerweb.com/">Eric</a>, <a href="http://braintraffic.com/">Kristina</a>, and <a href="http://cameronmoll.com/">Cameron</a> rock it out though. I’m sure it was amazing.</p>

<p>You can check out attendees thoughts from the event by <a href="https://twitter.com/search?q=%23aeansh&amp;src=typd">searching Twitter using the #aeansh hashtag</a>. I’ve <a href="https://storify.com/AaronGustafson/reactions-and-takeaways-from-my-aeansh-talk">collected reactions to my talk on Storify</a> for posterity as well.</p>
]]></content>
			</entry>
		
	
		
			<entry>
				<title type="html"><![CDATA[Learn From the Past, Enhance for the Future]]></title>
				<link href="https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future/"/>
				<updated>2016-03-04T16:33:57-06:00</updated>
				<id>https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future</id>
				<content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the closing keynote for the first EnhanceConf. I wanted to talk about voice and the future of “headless” user interfaces. Here’s what I had to say.</em></p>

<!-- more -->

<hr />

<p>Early last year, <a href="https://www.aaron-gustafson.com/notebook/how-to-apply-progressive-enhancement-when-javascript-seems-like-a-requirement/">a cry for help on Stack Overflow drew my attention</a>:</p>

<blockquote>
  <p>I’ve been trying to make my site … work fully without JavaScript, however, I’ve found myself in situations where I can’t honestly think how I would do some features without it.</p>
</blockquote>

<p>The submitter, JamHam, is certainly not alone in feeling this way. The ways we build websites change all the time. When I started out, it was pretty simple: you had HTML. Lots and lots of HTML. We also had Java applets, then Shockwave and Flash. Then we got some very basic stylesheet support. Then JavaScript.</p>

<p>As the years pressed on, the three major technologies underpinning the Web—HTML, CSS, and JavaScript—evolved and became even more powerful.</p>

<p>Things coalesced for a while in the early oughts before Jesse James Garrett re-christened a relatively obscure Microsoft creation, <code>XMLHttpRequest</code>, “AJAX” and set countless designers hearts aflutter with the promise of banishing the page refresh. At the heart of this revolution was JavaScript, and companies began betting their entire Web presence on its availability. Most learned that wasn’t such a good idea and began using it as an enhancement to the experience rather than a requirement.</p>

<p>After Ajax, there was HTML5, CSS3, and a host of new JavaScript APIs… the JavaScript frameworks—Angular, Knockout, Backbone, Ember, React… The ways we can create Web products just keep changing; sometimes slowly, but more often than not at such a speedy clip it leaves my head spinning.</p>

<p>The one thing I’ve learned however, being an “old man” in Web terms, is that web design is cyclical, just like everything else. <strong>The challenges we face building web products today are not new challenges.</strong> Moreover, the lessons we learned building similar products in the “Web 1.0” days pay dividends today and will continue to do so in the future.</p>

<p>When I started out on the Web, I had a 28.8 <abbr aria-label="kilobits per second">kbit/s</abbr> modem, but still had to support users on 14.4 <abbr aria-label="kilobits per second">kbit/s</abbr> connections. That’s half the speed I was used to running at. That may have been 20 years ago, but the lessons I learned about streamlining my HTML, optimizing images, and minimizing downloads has helped me immeasurably when dealing with high-latency mobile networks and excruciatingly slow “broadband” connections.</p>

<p>(I’m looking at you, every hotel ever.)</p>

<p>When I started out on the Web, I had an 800x600 monitor, but still had to support 640x480 screen resolutions. I learned the importance of prioritizing content long before media queries and flexbox enabled us to adapt our layouts on the fly. And while our computer screens keep getting bigger, mobile devices and wearables present the very same challenges I was tackling with 640x480, but in even tighter confines.</p>

<figure id="figure-2016-03-04-01">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/01.gif" alt="Screen sizes changing over time." />
</figure>

<p>When I started out on the Web, there was no JavaScript. All calculations, data processing, and dynamic functionality had to be handled by the server. I learned how to process web forms in Perl, later trading in my CGI scripts for PHP, Ruby, and Python. And while the vast majority of our users today have JavaScript baked into their browsers, I still rely on server-side fallbacks because I recognize that we don’t control the execution environment on the open Web.</p>

<blockquote>
  <p>The Web is the most hostile software engineering environment imaginable.<br />— Douglas Crockford</p>
</blockquote>

<p>You’re a savvy bunch, so I’m sure none of this is news to you, but I wanted to set the stage for what I’m really here to talk about. There’s a new cycle about to hit us and chances are you might not be thinking about it yet: Voice.</p>

<h2 id="i-the-headless-ui">I: The Headless UI</h2>

<p>Science fiction has often been a strong predictor of our technological future. HAL 9000 from <em>2001: A Space Odyssey</em> is probably the most (in)famous example of a computer that interacts with its users largely via voice. As a concept, the “talking computer” has appeared time and time again in space-age fiction—everything from <em>Red Dwarf</em> to <em>Interstellar</em>.</p>

<p>To function in the real world like they do on TV and in the movies, computers need two capabilities: Natural language processing (to understand what we say) and speech synthesis (to communicate, aurally, back to us).</p>

<figure id="figure-2016-03-04-02">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/02.gif" alt="Visual of a human and a computer conversing." />
</figure>

<p>Natural language processing has its roots in the 1950s, but many of these early speech models were limited because they were built around a series of hard-coded rules that the computers followed. In the 1980s, however, machine learning and real-time statistical analysis became possible.</p>

<p>As hardware capabilities continued to improve and computers became more powerful, they got better at recognizing the words we were saying to them. Eventually, and with enough processing power, they also began to assign meaning to words and could react accordingly.</p>

<p>As the years marched on, the overhead required to enable our projects to listen to our users has dropped significantly.</p>

<p>Listening is great, but true communication is bidirectional. Humans have been experimenting with speech synthesis since the late 1700s, but it wasn’t until the 1980s that we got a decent result though. By the 1990s, reasonably intelligible text-to-speech software was being rolled out alongside most operating systems as a core component of their assistive technology offerings: The “screen reader”. At present, screen readers are probably the best indicator of what the future of voice interaction will sound like.</p>

<p>When combined, the ability of a computer to listen and respond gave rise to virtual personal assistants like Siri, Cortana, Alexa, and more.</p>

<p>Over time, our customers will become more accustomed to and reliant on voice-based interactions with their computers and the Web. Enabling them to complete critical tasks without a visual user interface will be crucial for the long-term success of our Web-based products.</p>

<p>So how do you design a “headless” UI? That’s easy: You design the conversation.</p>

<h2 id="ii-interface-is-conversation">II: Interface is Conversation</h2>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>—we engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Let’s look at a few web page and interface component types to identify the kinds of conversations we trying to have with our users in each:</p>

<ul>
  <li><strong>Homepage</strong><br /> We’ve just met and I’m explaining what you can do on my site (and, in some cases, why it matters).</li>
  <li><strong>Contact Form</strong><br /> You’re asking or telling me something. I want to help you. It’s common courtesy for me to let you know how long it may take me to get back to you with a response; and for me to abide by that.</li>
  <li><strong>Product Page</strong><br /> I’m explaining what a particular object or service is, what it does, and how it will benefit you. I should “show” you why something is great rather than “tell”-ing you that it is because you’re immune to salesy <abbr aria-label="bullshit">BS</abbr>.</li>
  <li><strong>Status Update</strong><br /> I may prompt you with a question, but I’m here to listen. The floor is yours. (But I’m probably mining what you say for data so I can market to you later.)</li>
</ul>

<p>When we approach interfaces as conversations, we humanize our products and improve our users’ experiences. When we don’t, things can fall apart quickly…</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions. At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided. In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend.</p>

<p>The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do.</p>

<p>The text of our interfaces—especially form labels and responses—is just one small part of the content picture, but it’s a perfect example of how easy it can be to overlook conversation in our interfaces. There are many other types of content like product descriptions, marketing copy, legal statements, visualizations, video, audio, and more. Content is where experience begins. It’s the core that we seek to progressively enhance. It’s also the foundation upon which the voice-based experiences of the future will be based.</p>

<p>The more time and consideration we put into how our interfaces read, the better-positioned we will be to succeed in the future of headless UIs. Once stripped of its beautifully-crafted, responsive layout, engaging animations, and artful illustrations, does your site hold up?</p>

<hr />

<p>Back in 2006, <a href="http://www.dustindiaz.com/naked-day/">Dustin Diaz proposed CSS Naked Day</a>—a day when sites could be stripped of their visual design to showcase their content, semantics, and organization.</p>

<blockquote>
  <p>It will be a test case to see how usable your website is to others without a “design”.<br /> —Dustin Diaz</p>
</blockquote>

<p>“Design”, as Dustin was refering to it, is the visual design of a site, but design is not solely concerned with visual representations. Diving into etymology for a moment here, <em>design</em> comes from the Latin <i lang="la">designare</i> meaning “to mark out or indicate”. The purpose of design is not to make something pretty, it’s to clarify.</p>

<p>If the words we use form the basis of the conversations we have with our users, the semantics we employ clarify that meaning. Choosing elements with semantic value enriches our content, illuminating the meaning and intent of our words in order to overcome the limitations of text and bring it up to par with spoken language. After all, they may look the same visually, but there’s a big difference between these two statements:</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=different-meanings.html"></script>
<noscript><pre><code>&lt;p&gt;I &lt;em&gt;really&lt;/em&gt; want to be your friend.&lt;/p&gt;
&lt;p&gt;I &lt;i class=&quot;sarcasm&quot;&gt;really&lt;/i&gt; want to be your friend.&lt;/p&gt;</code></pre></noscript></div>

<p>Beyond using markup to clarify the intent of the words we write, we can use it to spell out relationships that are often represented visually. Dustin described one way we do this as part of the impetus for CSS Naked Day (emphasis mine):</p>

<blockquote>
  <p>In the spirit of promoting Web Standards along with good semantic markup and <em>proper hierarchy structures</em></p>
</blockquote>

<p>By “proper hierarchy”, Dustin is talking about the document outline. A document outline is created through use of heading elements (<code>h1</code>–<code>h6</code>). It provides a easy way to review the organization of our web pages and validate our source order decisions. It also helps us ensure the flow works, which is incredibly important in any conversation. It helps us get to the point, streamline our content, and remove distractions… all of which are a sign of respect to our users.</p>

<p>None of this is news, of course, content strategists have been recommending that we streamline our content since the dawn of the Web. Sadly, many folks didn’t heed that advice until they were forced to confront the often infuriating world of mobile. Smaller screens required focused content.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction. As part of their <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit">Alexa Skills Kit</a>, <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-voice-design-best-practices">Amazon offers a ton of recommendations for designing for voice</a>, many of which happen to be equally useful for sighted users.</p>

<h3 id="write-for-people">Write for People</h3>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://www.amazon.com/gp/product/0321988191/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321988191&amp;linkCode=as2&amp;tag=easydesign-20&amp;linkId=5INOUNG72ODCWZQV"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<blockquote>
  <ul>
    <li>Be clear.</li>
    <li>Be concise.</li>
    <li>Be honest.</li>
    <li>Be considerate.</li>
    <li>Write how you speak.</li>
  </ul>
</blockquote>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h3 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h3>

<p>When we are writing for our readers, we need to be familiar with their level of domain knowledge so we don’t frustrate or alienate them. For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user.</p>

<figure id="figure-2016-03-04-03">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/03.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/03.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/03.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/03.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<figure id="figure-2016-03-04-04">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/04.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/04.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/04.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/04.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<h3 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond"><strong>When Requesting Feedback, Make It Clear that the User Needs to Respond</strong></h3>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response. Labels like “What is your first name?” make it clear the user should respond.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=better-labels.html"></script>
<noscript><pre><code>&lt;label for=&quot;first_name&quot;&gt;What’s your first name?&lt;/label&gt;
&lt;input name=&quot;first_name&quot; id=&quot;first_name&quot;&gt;</code></pre></noscript></div>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=field-error.html"></script>
<noscript><pre><code>&lt;label for=&quot;first_name&quot;&gt;What’s your first name?&lt;/label&gt;
&lt;input name=&quot;first_name&quot; id=&quot;first_name&quot;
       aria-describedby=&quot;first_name-error&quot;
       &gt;
&lt;em id=&quot;first_name-error&quot;&gt;
  Without your first name, I won’t know how to address you.
  Could you please provide it?
&lt;/em&gt;</code></pre></noscript></div>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="when-asking-a-user-to-choose-clearly-present-the-options"><strong>When Asking a User to Choose, Clearly Present the Options</strong></h3>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=radio-label.html"></script>
<noscript><pre><code>&lt;input type=&quot;radio&quot; name=&quot;agree&quot; id=&quot;agree_yes&quot; value=&quot;yes&quot;&gt;
&lt;label for=&quot;agree_yes&quot;&gt;Yes&lt;/label&gt;</code></pre></noscript></div>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=fieldset.html"></script>
<noscript><pre><code>&lt;fieldset&gt;
  &lt;legend tabindex=&quot;0&quot;&gt;Do you agree to the terms of service for this site?&lt;/legend&gt;
  
  &lt;input type=&quot;radio&quot; name=&quot;agree&quot; id=&quot;agree_yes&quot;  value=&quot;yes&quot;&gt;
  &lt;label for=&quot;agree_yes&quot;&gt;Yes&lt;/label&gt;
  
  &lt;input type=&quot;radio&quot; name=&quot;agree&quot; id=&quot;agree_no&quot;  value=&quot;no&quot;&gt;
  &lt;label for=&quot;agree_no&quot;&gt;No&lt;/label&gt;
&lt;/fieldset&gt;</code></pre></noscript></div>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It does not, however, identify the <code>nav</code> element as being for navigation when encountered naturally in the flow of the document. For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=navigation.html"></script>
<noscript><pre><code>&lt;nav id=&quot;nav&quot; tabindex=&quot;0&quot; aria-labelledby=&quot;nav-title&quot;&gt;
  &lt;h1 id=&quot;nav-title&quot; class=&quot;hidden&quot;&gt;Here’s what you can find on this site:&lt;/h1&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;/about/&quot;&gt;&lt;b class=&quot;hidden&quot;&gt;A Bit &lt;/b&gt;About&lt;b class=&quot;hidden&quot;&gt; Me&lt;/b&gt;&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;/notebook/&quot;&gt;&lt;b class=&quot;hidden&quot;&gt;Entries in My &lt;/b&gt;Notebook&lt;/a&gt;&lt;/li&gt;
    …
  &lt;/ul&gt;
&lt;/nav&gt;</code></pre></noscript></div>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear.</h3>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>Here in the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/09.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/09.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/09.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/09.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/10.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/10.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/10.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/10.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h3 id="ask-only-necessary-questions">Ask Only Necessary Questions</h3>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/11.jpg&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/11.jpg&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/11.jpg&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/11.jpg&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/12.jpg&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/12.jpg&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/12.jpg&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/12.jpg&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
<img src="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/13.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" srcset="https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/13.png&amp;resize_w=1920&amp;container=focus&amp;refresh=2592000 1920w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/13.png&amp;resize_w=600&amp;container=focus&amp;refresh=2592000 600w,https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?url=https://www.aaron-gustafson.com/i/posts/2016-03-04/13.png&amp;resize_w=320&amp;container=focus&amp;refresh=2592000 320w" sizes="100vw" alt="" />
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Even in the States, most developers would only know how to label the first of those three boxes. (They are area code, exchange or central office code, and line number, if you’re interested.)</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<h2 id="iii-future-enhancements">III: Future Enhancements</h2>

<p>Paying attention to how our interfaces read is critical to success in the future of voice-based interactions. Thankfully, we already view content as the centerpiece of every progressively enhanced experience. But we can go further.</p>

<p>Both Microsoft and Amazon have given us the tools to voice-enable our websites beyond the HTML we present. Amazon has chosen to do this via a dedicated JSON API, through which we can “teach” Alexa “skills”. Using this API, you can enable your users to access core site functionality through the Echo, FireTV, or any other device that has integrated the Alexa Voice Service.</p>

<p>Microsoft has taken a slightly different approach. Using a relatively simple XML format, they have enabled us to teach Cortana new commands that tie directly into our website.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=meta.html"></script>
<noscript><pre><code>&lt;meta name=&quot;msapplication-cortanavcd&quot;  content=&quot;http://myapp.io/vcd.xml&quot;&gt;</code></pre></noscript></div>

<p>All we need to do is include a <code>meta</code> tag pointing to an XML file that details the commands (and variations) and, when a user installs the site as a hosted app, Cortana picks up the new commands automatically. Those commands, when issued, can open a specific page or even kick off JavaScript methods in the target page.</p>

<div><script src="https://gist.github.com/6f5b7c0f0c072631a908.js?file=vcd.xml"></script>
<noscript><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;VoiceCommands xmlns=&quot;http://schemas.microsoft.com/voicecommands/1.2&quot;&gt;
  &lt;CommandSet xml:lang=&quot;en-us&quot; Name=&quot;groupPost&quot;&gt;
    &lt;CommandPrefix&gt;Group Post&lt;/CommandPrefix&gt;
    &lt;Example&gt;Group Post add note&lt;/Example&gt;
    &lt;Command Name=&quot;addNote&quot;&gt;
      &lt;Example&gt;add a note {message} using group post&lt;/Example&gt;
      &lt;ListenFor RequireAppName=&quot;BeforeOrAfterPhrase&quot;&gt;[please] 
        add a note [that] {noteSubject}&lt;/ListenFor&gt;
      &lt;Feedback&gt;adding {noteSubject} to Group Post&lt;/Feedback&gt;
      &lt;Navigate Target=&quot;/addNote.htm&quot;/&gt;
    &lt;/Command&gt;
    &lt;PhraseTopic Label=&quot;noteSubject&quot; Scenario=&quot;Dictation&quot;&gt;&lt;/PhraseTopic&gt;
  &lt;/CommandSet&gt;
&lt;/VoiceCommands&gt;</code></pre></noscript></div>

<hr />

<p>We are just starting to scratch the surface of what’s possible in voice-enabling the Web, but it’s exciting to see how some companies are addressing this opportunity. It’s always interesting when things come full circle and we see how lessons we learned early on in the Web remain applicable, not matter how much or quickly things seem to change. Seeing this pattern repeat time and time again is why I’m so drawn to the philosophy of progressive enhancement; it’s not only concerned with supporting the past… it’s setting us up for success in the future.</p>
]]></content>
			</entry>
		
	
		
	
		
	
		
			<entry>
				<title type="html"><![CDATA[Planning Adaptive Interfaces: The Workshop]]></title>
				<link href="https://www.aaron-gustafson.com/notebook/planning-adaptive-interfaces-the-workshop/"/>
				<updated>2016-02-21T17:56:05-06:00</updated>
				<id>https://www.aaron-gustafson.com/notebook/planning-adaptive-interfaces-the-workshop</id>
				<content type="html"><![CDATA[<p>For the last few years I’ve been running a workshop alternately titled “Planning Adaptive Interfaces” or “Beyond Responsive”, depending on the conference. It’s been one of my favorite workshops to run for a number of reasons, but before I get into that, let me explain what it is and how it works.</p>

<!-- more -->

<p>I think we all recognize how much Ethan’s seminal article <a href="http://alistapart.com/article/responsive-web-design">“Responsive Web Design”</a> (and <a href="https://abookapart.com/products/responsive-web-design">his follow-up book</a>) shook up our industry. It changed the way we look at visual design and kindled (or in some cases re-kindled) an interest in catering an experience to mobile devices. But simply incorporating responsive design’s three core strategies—fluid grids, flexible media, media queries—is not the goal; meeting our user’s needs is. Responsive design is not an end in itself… it’s just the beginning.</p>

<p>We need to embrace the heterogenous nature of the Web—myriad connected devices with vastly different screen sizes (if they even have screens), network connectivity, and capabilities in use by countless individuals, each with their own special needs—and craft experiences that will work anywhere at any time. We need to build robust systems that adapt in ways far beyond aesthetics. I designed this workshop to explore the rich variety of use cases that often get overlooked in the course of building web projects and to show how we can begin considering them as early as possible.</p>

<p>When I was starting out, I gave “workshops” that basically amounted to a half-day or (worse) a full day for folks to listen to me blather on about one topic or another. People liked them, but I wouldn’t call them fun. And, in hindsight, I question how much value people got from an extended survey of what’s possible without the opportunity to put that knowledge to use. Workshops should encourage attendees to get their hand dirty.</p>

<p>I kick this workshop off with a relatively brief discussion of the considerations that we should be aware of—beyond screen size and pixel density. I also provide examples of how to adapt interfaces so they rise to meet our customers’ needs. Then I throw out a list of common interface patterns—modals, tabs, etc.—and turn the floor over to the attendees, asking them to build small teams that each examine a single pattern in detail with these considerations in mind. They then spend the rest of the workshop planning out how that interface would adapt to consider factors like accessibility, screen dimensions, device capabilities, JavaScript availability, and so on. All the while, I circulate among the groups, asking and answering questions, pressing them to go a little further with each iteration. Some teams sketch, some prototype, and all spend a lot of time debating, which is awesome!</p>

<p>I leave the last hour or so for a group discussion of what each team’s accomplished. It gives them a chance to talk through their approach, what they learned, what their pain points were, and how they overcame them. Not does it celebrate their work, but it helps the other attendees discover novel ways to approach these common UI constructs.</p>

<p>It’s been a blast and I have learned so much from the teams I’ve coached. Each workshop is completely different because each group of attendees is completely different. I’ve run it with groups ranging from 12 to 120, for internal teams at large companies to mixed audiences from all over the world. Everyone who has attended one of these workshops has brought a unique perspective and helped us all get better at our jobs. That’s been one of the best parts of this experience for me.</p>

<p>If a workshop like this sounds up your alley, I’ll be giving it a few more times in 2016. Your next opportunity will be at <a href="http://enhanceconf.com/workshop.html">EnhanceConf in London in early March</a>. Later in the year, I’ll be giving it as part of <a href="https://buildright.io/maker-series/2016/aaron-gustafson">Sparkbox’s Build Right: Maker Series</a>. I’d love the opportunity to work with you if you can make it!</p>
]]></content>
			</entry>
		
	
		
			<entry>
				<title type="html"><![CDATA[Progressive Enhancement Gets a Conference]]></title>
				<link href="https://www.aaron-gustafson.com/notebook/progressive-enhancement-gets-a-conference/"/>
				<updated>2016-02-15T09:00:51-06:00</updated>
				<id>https://www.aaron-gustafson.com/notebook/progressive-enhancement-gets-a-conference</id>
				<content type="html"><![CDATA[<p>On March 4th, I’ll be in London to give the closing talk at <a href="http://enhanceconf.com/">EnhanceConf</a>, the first conference dedicated progressive enhancement. Over the last few months, I’ve been talking to the conference’s organizer, <a href="https://twitter.com/simonmcmanus">Simon McManus</a>, quite a lot. He’s put a lot of thought into the conference and I thought it might be interesting to  interview him so he could share his motivations and hopes for the event.</p>

<!-- more -->

<p><b class="interview__attribution">Me:</b> As a philosophy, progressive enhancement has been around for more than a dozen years. Why do you think it needs a conference now?</p>

<p><b class="interview__attribution">Simon:</b> I first started thinking about EnhanceConf in 2014. At the time, Tom Dale had declared progressive enhancement dead and I had just heard Henrik Joreteg telling his Single Page Story.I was hearing lots of talk about progressive enhancement being hard and expensive when my experience showed quite the opposite.</p>

<p>It’s been fascinating to watch how views have changed since, Tom Dale now loves progressive enhancement and Henrik likes to do as much of his rendering at build time as possible.</p>

<p>As the web continues to grow in weird and wonderful ways techniques like progressive enhancement just keep giving more and more value.</p>

<p><b class="interview__attribution">Me:</b> What does progressive enhancement mean to you?</p>

<p><b class="interview__attribution">Simon:</b> I try to build applications that provide the best possible experience to the end user. Regardless of who they are, where they are or what device they are using. For me, that means using progressive enhancement in every part of the stack.</p>

<p>Progressive enhancement is about so much more than whether an app work with JavaScript turned off, realising we don’t have control over the runtime environment and building applications in the most robust way possible is far more important.</p>

<p><b class="interview__attribution">Me:</b> Do you think it’s an approach that everyone should use on every web project?</p>

<p><b class="interview__attribution">Simon:</b> I guess that depends on what you mean by a web project. In my mind to work on the web, you have to give up that illusion of control. You need to assume as little as possible about the device or user and for me that fits very well with progressive enhancement.</p>

<p>Web technologies transcend the capabilities of any one device with their reach alone, it seems strange to me when people use them but don’t take full advantage.</p>

<p><b class="interview__attribution">Me:</b> If a web designer or developer is only passingly familiar with progressive enhancement and is considering coming to the event, what should they expect to get out of it?</p>

<p><b class="interview__attribution">Simon:</b> These are probably the people with the most to benefit from EnhanceConf.</p>

<p>We are going to start the day looking at why progressive enhancement is still important on the modern web, so that should provide a nice intro for anyone who is not already familiar with progressive enhancement.</p>

<p><b class="interview__attribution">Me:</b> What about a seasoned practitioner who already applies this philosophy to their work?</p>

<p><b class="interview__attribution">Simon:</b> Originally, EnhanceConf was a very selfish idea. I wanted to learn more about the tools and techniques being in use in industry: Over the last few years contracting I’ve seen many in use in that just weren’t surfacing at conferences.</p>

<p>EnhanceConf is about the state of the art in progressive enhancement, I’d like to think EnhanceConf will be the perfect event for such people to come together and learn from one another.</p>

<p><b class="interview__attribution">Me:</b> What if the person thinks progressive enhancement is a waste of time?</p>

<p><b class="interview__attribution">Simon:</b> I’d really like to encourage these people to come along to the event, I think it’s important their voice is a part of this discussion so that we can learn from each other and move forward together.</p>

<p>With an open mind I think they should have a really good time, they might hear some viewpoints they disagree with, but there will be lots of opportunities for Q&amp;A to discuss those topics in detail.</p>

<p><b class="interview__attribution">Me:</b> As a hyper-focused event, there’s a risk of it being a bit of an echo chamber. Have you taken steps to mitigate that possibility?</p>

<p><b class="interview__attribution">Simon:</b> I hope by being a hyper-focused event we can move beyond the bikeshedding that so often surrounds such discussions.</p>

<p>But yes. I have taken a couple of steps to mitigate an echo chamber:</p>

<ol>
  <li>
    <p><strong>Duplicate content</strong>
If you take all the talks about progressive enhancement and put them all on the same day you would end up with a fair amount of similar content. There will be no generic talks about progressive enhancement at EnhanceConf. Each talk will dig into real examples to provide unique tales from the trenches.</p>
  </li>
  <li>
    <p><strong>Preaching to the choir</strong>
I’ve been reaching out to lots of different communities around London to bring as many voices into the discussions as possible. The other day I was at the Meteor London meetup talking about EnhanceConf. Tableflip (the organisers) even bought tickets for their whole company!</p>
  </li>
</ol>

<p>The event is also being recorded so anyone not at the event will be able to watch all the talks and Q&amp;A.</p>

<p><b class="interview__attribution">Me:</b> You’re modeling the format of the event—four acts, each comprising three twenty-minute talks and a group Q&amp;A session—on Responsive Day Out. What was the draw of that approach?</p>

<p><b class="interview__attribution">Simon:</b> Yes, we get to hear lots of different viewpoints and then bring the speakers together for a Q&amp;A. This should allow new viewpoints to emerge from discussions and join related threads. It also means we get to spend each section focusing on a particular area.</p>

<p><b class="interview__attribution">Me:</b> Can you talk a bit about your speaker selection process?</p>

<p><b class="interview__attribution">Simon:</b> I had lots of people in mind to talk at EnhanceConf. To ensure we heard a wide range of viewpoints we also opened a call for proposals to which we received some superb submissions.</p>

<p>I was fortunate to have some trusted advisors who helped me out throughout the process. I’m really pleased with how the line-up turned out.</p>

<p><b class="interview__attribution">Me:</b> When the event is done and dusted, what are you hoping will happen?</p>

<p><b class="interview__attribution">Simon:</b> I’d quite like a holiday! :D</p>

<p>But seriously, I hope we can demonstrate how to maximise the benefits and minimise any costs associated with progressive enhancement.</p>

<p>If at the end of EnhanceConf we had a reasoned and nurturing community able to take discussions forward that would be a fine outcome. :)</p>

<p><b class="interview__attribution">Me:</b> Do you think there will be another EnhanceConf?</p>

<p><b class="interview__attribution">Simon:</b> EnhanceConf is the first conference I’ve organised. It’s been an unfathomable amount of work and financial risk to get this far and it’s mostly been done in my evenings and weekends. That said, it has been quite fun.</p>

<p>I’d like to do some traveling this year, maybe 2018?</p>

<hr />

<p>EnhanceConf will take place March 4th at the <a href="http://www.thersa.org/">RSA House</a> in London. <a href="http://enhanceconf.com/tickets.html">Tickets are available on the conference website</a>. I will also be giving <a href="http://enhanceconf.com/workshop.html">a one-day workshop entitled Planning Adaptive Interfaces</a> on March 3rd as part of the conference. Seating is limited.</p>

<p>EnhanceConf is offering a small number of educational scholarships. For more information on the scholarships and how to apply, check out <a href="https://simonmcmanus.wordpress.com/2016/02/14/enhanceconf-scholarship/">Simon’s post about the program</a>.</p>
]]></content>
			</entry>
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
	
		
			<entry>
				<title type="html"><![CDATA[Apple Support: Honeybadger]]></title>
				<link href="https://www.aaron-gustafson.com/notebook/apple-support-honeybadger/"/>
				<updated>2016-01-26T16:34:17-06:00</updated>
				<id>https://www.aaron-gustafson.com/notebook/apple-support-honeybadger</id>
				<content type="html"><![CDATA[<p>My iPhone fell clumsily out of my pocket when I was sitting down in the kitchen the other day. <em>Thwack!</em> It fell face-first onto the tile from my seated position a mere 18 inches up. Of course the screen cracked. Protective case be damned, the cracks spread across the screen like a spider web cast from razor blades.</p>

<p>I was crestfallen.</p>

<!-- more -->

<p>Thankfully, apart from the very finger-unfriendly hellscape the screen had become, the rest of the phone completely functional. If I was careful where and how I swiped, I could do pretty much anything I needed to. And I did exactly that for a few days while I looked into my options for fixing it.</p>

<p>It was an iPhone 6 I purchased right when they came out, so a warranty repair was not an option. And I don’t see the point of paying for phone insurance or Apple Care<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>, so I was on my own to cover the cost of the repair. No biggie; it was my fault for putting it in the loose pocket of my pajama pants anyway.</p>

<p>I began researching my options:</p>

<ol>
  <li>I could cover the broken phone with a rugged case and just deal with it.</li>
  <li>I could use one of our old iPhones until the next version came out.</li>
  <li>I could upgrade my phone with AT&amp;T.</li>
  <li>I could self-repair as <a href="http://www.imore.com/iphone-6-screen-replacement-how-to">the process is pretty straightforward</a>, but in talking with a friend who repairs smartphones for a living, I discovered the replacement screens weren’t that great.</li>
  <li>I could have Apple repair it.</li>
</ol>

<p>Apple offers screen repair for $109, which isn’t too bad, but that takes a few days to ship the phone back and forth. They offer an expedited option where they just send you a new phone, but at $299, it seemed silly.</p>

<p>I contacted the local authorized Apple repair center to see if they could do the repair, but it turns out that they would just be sending it on to Apple anyway, so it seemed like my best bet would be to go back to the source. After all, who could know better how to replace a broken iPhone screen (<a href="https://www.etechparts.com/lcd-screen-and-digitizer-full-assembly-with-small-parts-black-for-iphone-6.html">and digitizer, since they’re fused</a>) than Apple Support?</p>

<p>I chatted with an Apple Support rep about doing the repair and confirmed that the repair would cost $109. The rep told me, however, that they would need to authorize my card for $299—the out-of warranty replacement cost—in case they discovered other damage to the phone. I agreed (it was my only option) with the understanding that Apple would run some diagnostic utilities to determine what (if any) additional issues the phone might have.</p>

<p>A day or two later I got the mailer to send the phone to Apple, I shipped it to them and waited. They confirmed receipt of the phone the next day and, two days later, I got an email saying the phone was en route back to me. I was thrilled with the quick turnaround!</p>

<p>Then Kelly asked me why Apple had charged us $329. I said I wasn’t sure. The authorization was for $299, but the repair service was only supposed to be $109 (plus tax and shipping, naturally). Perhaps they billed the whole amount and then returned the unused portion in a separate transaction. We decided to wait and see what would happen.</p>

<p>The next day, a phone arrived. I say <em>a</em> phone because it was not <em>my</em> phone. Apple Support had sent me a refurbished replacement phone and charged me the full replacement cost. <em>Why?</em> “After thorough diagnostic testing, it has been determined that a replacement iPhone (enclosed) is necessary.” Vague.</p>

<p>I was curious what their tests had revealed. <span data-quotable="">What gremlins were lurking in my heretofore fully-functional device?</span> I decided to investigate with another support rep and was not thrilled with what I found.</p>

<p><em>Note: I spent the next few hours in a chat session with two different reps at Apple Support. Both were incredibly friendly and did everything in their power to help me get to the bottom of why my screen repair had turned into a complete replacement. Credit where credit is due.</em></p>

<p>In the conversation with the first rep, Josh, I made it clear that the phone was working perfectly before I sent it to them. It merely needed a new screen/digitizer. I offered that I was disappointed to see that they’d replaced it without explaining what would require that level of remediation <em>and</em> without giving me the option to have the phone returned to me as-is. From the beginning, he clearly saw where I was coming from:</p>

<blockquote>
  <p>Oh good grief, I’m really sorry you’ve had to deal with this. That’s not at all what we want from this process.</p>
</blockquote>

<p>After a few minutes of doing some research, he came back to me:</p>

<blockquote>
  <p>So basically from what we’ve been discussing, the service center does run a plethora of tests on the phone once it’s sent in. That’s to be sure that it’s working properly in all ways, rather than just the screen repair itself, though trust me, I do fully understand that the only thing you wanted was the screen to be repaired, so I’m just compiling all of the data to see what happened.</p>
</blockquote>

<p>A few minutes later…</p>

<blockquote>
  <p>[I]t’s looking like basically what ended up happening was there were tests that were run which will test the phone for a bit of additional damage than the tests that were run. From there, they look into what will give you the longest lasting phone, basically so that you don’t run into an issue with what their diagnostics tests detected down the road, and then need to pay again for it to be repaired.</p>
</blockquote>

<p>I replied</p>

<blockquote>
  <p>[That] assumes I plan to keep the phone long enough for it to become an issue… I appreciate them looking into potential issues, but making unilateral decisions about how to proceed is not good customer service in my opinion. Letting someone know what the issue is and how much the repair would cost is just common courtesy. Even my car dealership does me that courtesy.</p>
</blockquote>

<p>Josh was right there with me:</p>

<blockquote>
  <p>Exactly, which I know is not always a proper assumption, and I can entirely agree. I’m even still looking into additional data for you. I really don’t like how this was handled, so I’m seeing if I can come across anything additional on the matter.</p>
</blockquote>

<p>He asked if I knew of any other damage to the phone and I told him that it was always in a case and I was not aware of a single other issue with the phone, cosmetic or otherwise.</p>

<p>He was completely empathetic:</p>

<blockquote>
  <p>I’m really sorry about this whole thing, Aaron. It’s looking like some sort of damage was found with the phone, which is what caused that price to be charged, rather than just the screen repair, so ultimately they decided that it would give you a longer lasting phone to replace it, so that way you wouldn’t have to deal with the hassle of having additional issues down the road. Honestly, I cannot express enough how much I understand the situation, and especially at least being informed or asked if that can be done. That’s just why the full out of warranty/replacement charge has to be held initially, is so that they have authorization to run those tests, and if needed, replace it, rather than just repair it. I’m so sorry that the process wasn’t elaborated to you, and that they didn’t at least let you know of what was going on.</p>
</blockquote>

<p>I reiterated that someone really should have <em>asked</em> if I wanted the additional work done. I understand Apple’s “heart” might be in the right place, but they failed to do what I had hired them to do. They didn’t consider my wishes or expectations in their process at all. Nor did they give me an opportunity to decline the replacement and get my broken phone back.</p>

<p>Josh pleasantly informed me that by agreeing to the repair, I was out of luck:</p>

<blockquote>
  <p>[Replacement] was actually authorized to be used when you initially setup the payment. When the full $299 (plus taxes and shipping) was held from your card, that was authorized that if needed, it could be used for the repair if additional damage was found. Since it was found, they used the remainder of that money to replace the phone instead.</p>
</blockquote>

<p>I countered:</p>

<blockquote>
  <p>I understand that you required the $299 + tax in order to start the repair, but that was my only option if I wanted you guys to do the $109 screen repair. Like I said, had I suspected anything else was going to be done to the phone, I would have taken my chances buying a replacement screen and doing the repair myself. … I typically replace my phone every other version, so I would have limped along with the broken screen even rather than pay the full replacement fee.</p>
</blockquote>

<p>Josh, to his credit, was still on my side:</p>

<blockquote>
  <p>Right, trust me, I fully understand, or alternatively we could have taken it into the local Apple Authorized Service Provider, which would have been able to diagnose the phone as well in order to determine what had to be done, and then give you a price right then and there. … I’ve actually covered cracked screens in cling wrap so that I didn’t need to risk furthering the damage, or hurting myself. I can also fully understand the process of not expecting that there was any further damage, since you were able to sue the phone just fine, and that’s why you ended up getting it setup that way.</p>
</blockquote>

<p>Ultimately, however, it didn’t really matter:</p>

<blockquote>
  <p>Basically, again, as much as I wish there was something that could be done on the matter in order to basically reverse what happened, it’s just not possible. Since it was authorized when it was initiated, and I do see where the previous advisors let you know that the full charge would be taken if additional damage was found, but if the only damage found to the phone was the screen cracks, then all but the screen repair fee of $109 plus taxes and shipping would be reimbursed. It’s just that additional damage was found, which is what caused that full charge to be taken.</p>
</blockquote>

<p>After a bit more back-and-forth, Josh recommended I file a complaint with Apple (I have), said he would make sure the process was reviewed internally, and connected me with a Senior Advisor, Alexander, to help me get a few more details regarding the “damage” that prompted the replacement. I thanked him for his time and for his empathy toward my situation.</p>

<p>The next few minutes involved getting Alexander up to speed with what had happened. He was equally helpful:</p>

<blockquote>
  <p>Okay, I know how a sudden cost like this $299 can be concerning, especially when you don’t feel adequately informed on the situation. I can certainly clarify anything and get this figured out with you though.</p>
</blockquote>

<p>Then he dropped the bombshell:</p>

<blockquote>
  <p>So the main bit of information that I want to address is not that the phone was replaced to address issues that may arise down the road. In this case, a screen replacement was attempted and did not yield a functioning device. When that occurs, our only option is to replace the device. I do see from your chats with Michelle and Teresa that they advised this was the procedure that we have</p>
</blockquote>

<p><em>Wait. What?!</em> They didn’t find any problems. In replacing the screen, the tech bricked the phone.</p>

<blockquote>
  <p>No, not at all. Just that they were unable to have a fully functioning unit after a screen replacement. That does not mean that the tech bricked the phone or messed up when replacing the screen, it means the phone was not able to work after the screen was replaced.</p>
</blockquote>

<p>Um, sounds to me like they bricked my phone. Alexander tried to clarify, but was ultimately saying the same thing:</p>

<blockquote>
  <p>While the issue was only a cracked screen, that does not mean that the screen can be replaced and yield a functioning device. Unfortunately we can never know if a screen replacement will work until we try.</p>
</blockquote>

<p>So… iPhones are only <em>occasionally</em> repairable. In other words, it’s a crapshoot. Comforting. No one had mentioned that they could brick the phone when attempting to repair it:</p>

<blockquote>
  <p>I was never advised that the repair could yield a non-functioning device. This is even more strange than I expected.</p>
</blockquote>

<p>Alexander towed the company line:</p>

<blockquote>
  <p>I’m looking at the chats you had with us when setting up the repair, and both advisors did say how it could be $299. I also don’t see anything from either one that says the depot would reach out to you if the repair price was not going to be $109. I’m really sorry that this happened to you Aaron, but this is how our process works and everything looks to have been done correctly here. … I see them saying that they will attempt to replace the screen and if that works it would be a $109 repair. If there were additional issues, it would cost more up to the $299 max for a full replacement unit.</p>
</blockquote>

<p>I clarified that they had said it <em>could</em> cost more. There’s a difference between “could” and “would”. I mentioned that I could have just kept the broken phone and upgraded with AT&amp;T and spent less money. Alexander didn’t miss a beat:</p>

<blockquote>
  <p>That certainly was an option you could have taken Aaron, and I do sympathize with not taking that option to end up paying more than you expected. I really wish the repair process was clearer for you, and I can only advise that you leave some feedback about the repair process to us at Apple Feedback. I don’t see any mention in these chats of the depot contacting you if the cost would be more nor an advisor stating that would be the case.</p>
</blockquote>

<p>I stuck to my guns:</p>

<blockquote>
  <p>I agree they didn’t state that would happen, but I think in the repair world it’s pretty common. … Explicitly stating that would not happen might be a good thing.</p>
</blockquote>

<p>Alexander conceded that the process was less than ideal:</p>

<blockquote>
  <p>I don’t disagree, but that does vary from place to place and device to device. Our procedures are in line with most of the mobile phone world on this though. I will certainly leave some feedback for those advisors to be more clear about this process when a repair is set up though.</p>
</blockquote>

<p>We talked for a few more minutes, but it was clear I was out of options. I could file a complaint with Apple (and have), but I am skeptical they even pay attention to that stuff. I know they don’t chime in on their own forums. My only other option was to share my story with you, in hopes you might avoid a similar situation.</p>

<p>So consider yourself warned: If you send your phone to Apple for something as simple as a screen repair, they just may brick your phone and charge you for the convenience. Oh and the replacement phone only has a 90-day warranty. <em>Hooray!</em></p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>This is the first device I’ve broken in more than a decade of (ab)using expensive smartphones. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
			</entry>
		
	
		
	
		
	
		
	
		
	
		
	
		
	
</feed>
