<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Progressive Enhancement | Aaron Gustafson]]></title>
  <link href="http://aaron-gustafson.com/notebook/tags/progressive-enhancement/atom.xml" rel="self"/>
  <link href="http://aaron-gustafson.com/"/>
  <updated>2015-03-04T20:11:16-05:00</updated>
  <id>http://aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Who Should Pay?]]></title>
    <link href="http://aaron-gustafson.com/notebook/who-should-pay/"/>
    <updated>2015-02-18T23:35:06-05:00</updated>
    <id>http://aaron-gustafson.com/notebook/who-should-pay</id>
    <content type="html"><![CDATA[<p>In more than a handful of conversations lately, it’s become quite clear that we, the web development community, are prioritizing our own convenience and our own time over that of our users. With our industry’s focus on “user-centered design”, you might find that hard to believe, but it’s true.</p>

<!-- more -->


<p>Here’s one example. In reaction to <a href="/notebook/css-variables-are-a-bad-idea/">my post on why I think CSS variables are a bad idea</a>, <a href="http://sass-lang.com">SASS</a> core team member <a href="https://twitter.com/chriseppstein/">Chris Eppstein</a> had this to say:</p>

<p>{% tweet <a href="https://twitter.com/chriseppstein/status/567756897105620992">https://twitter.com/chriseppstein/status/567756897105620992</a> %}</p>

<p>Fundamentally, I agree with his sentiment: A preprocessor should <em>not</em> be a requirement for authoring CSS. Thankfully, <em>it never was</em>; you can build amazing things using only hand-authored CSS. And if you find a preprocessor helpful to your process for one reason or another, great. But using a preprocessor never has been (nor should it ever be) a requirement.</p>

<p>But Chris was not railing against preprocessors. Instead, he is echoing a sentiment held by many people in the preprocessor community. He feels CSS is not as powerful as it could/should be and he hopes that one day soon preprocessors won’t need to exist because CSS will have all of the features they offer natively. Like variables.</p>

<p>I used to feel that way. I used to want variables… and mixins… and functions… and loops… and declaration block-level inheritance. But I’ve changed my mind.</p>

<p>Don’t get me wrong, I love these constructs. I use them nearly every day in the SASS I write and I am incredibly thankful for the hard work that has gone into their creation and maintenance.  Chris alone has probably saved me several weeks worth of work over the last four years through his contributions to SASS and <a href="http://compass-style.org/">Compass</a>. I definitely owe him a beer (or three).</p>

<p>Ok, so if my issue is not with the idea of programmatically generating styles, why would I not want these to be part of CSS, the <i>lingua franca</i> for design on the Web? Well, it’s pretty simple: Converting all of these constructs into something that is actionable by the browser takes time and processing power. Someone has to pay that cost and I wouldn’t feel right passing that cost on to my end users if there are better options.</p>

<p>This is a topic I bring up often in my conference talks and workshops: Every decision we make affects the user experience in some way.</p>

<p>When we add another JavaScript library or plugin, it’s no big deal from our perspective. We tend to have fast connections and faster processors. For our users it’s another story: It’s one more thing to request. One more thing to download. One more script to parse. One more thing holding up page rendering. One more reason to leave our site and seek out a competitor who actually values their time.</p>

<p>When we hide an <code>img</code> in the small screen version of our responsive design using <code>display: none</code>, the cost to us is quite minimal. It’s just one little declaration. What’s the harm? But the cost to our end users is quite significant: Longer load times, slower performance, and (in some cases) in real dollars if they are on a <a href="http://blog.kaspersky.com/cost-aware/">metered data connection</a>. And they don’t even get to see the image they paid for!</p>

<p>When we decide to build a site using a front-end JavaScript MVC framework, it can make the development process go so much faster for us and we can reduce our need for a robust back-end infrastructure. I mean everyone has JavaScript these days… <a href="/notebook/a-fundamental-disconnect/">the browser is the new VM</a>. But when we do this, our users suffer because we don’t give their browsers real HTML. Instead we force them to download a hefty framework so we can move all of the processing we would normally handle on a much faster, dedicated server to their questionably-capable machine instead. Oh, and if the browser encounters an error while parsing or executing the JavaScript execution, they don’t get anything at all. Welcome to the Modern Web™!</p>

<hr>


<p>When I look around, I see our community spending a lot of time coming up with new tools and techniques to make our jobs easier. To ship faster. And it’s not that I’m against efficiency, but I think we need to consider the implications of our decisions. And if one of those implications is making our users suffer—or potentially suffer—in order to make our lives easier, I think we need to consider their needs above our own.</p>

<p>So yes, I would love a world where preprocessors are unnecessary, but I would much rather spend a few seconds (or even a few minutes) transcompiling my SASS into CSS in order to save my users even a few milliseconds. It’s the same reason I optimize my images, minify my JavaScript, use Gzip, and lazy load design and experience enhancements only in contexts where they provide a real benefit.</p>

<p>Our users should never foot the bill for our convenience. We need to put their needs above our own.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Three Worthwhile Posts on Progressive Enhancement]]></title>
    <link href="http://aaron-gustafson.com/notebook/three-worthwhile-posts-on-progressive-enhancement/"/>
    <updated>2015-02-13T10:14:40-05:00</updated>
    <id>http://aaron-gustafson.com/notebook/three-worthwhile-posts-on-progressive-enhancement</id>
    <content type="html"><![CDATA[<p>Jason Garber has penned a series of posts on progressive enhancement. Here’s a quick rundown on what they cover and why you should read them.</p>

<!-- more -->


<h2><a href="http://sixtwothree.org/posts/designing-experience-layers">Designing Experience Layers</a></h2>

<p>In his first post, Jason picks up on a drumbeat I’ve been hammering on for years: we need to consider experience a continuum, not a monolithic thing.</p>

<blockquote><p>Today’s Web makes no guarantees. Every bit of code—HTML, CSS, and JavaScript—shipped from a server across the wire acts as a suggestion as to how the browser should interpret and display content. More often than not, everything works planned, but for any number of reasons, a browser could fail to request or render a particular asset.</p></blockquote>

<p>In other words, get to know <a href="http://adaptivewebdesign.info/1st-edition/chapter-1.html#adapt-or-die">fault tolerance as it applies to web design</a> and <a href="http://aaron-gustafson.com/notebook/a-fundamental-disconnect/">don’t make any assumptions about how your content will be rendered/experienced</a>.</p>

<p>His conclusion is an important one:</p>

<blockquote><p>Approaching design through the lens of experience layers is the design strategy for the Web; one that’s better for users and designers alike.</p></blockquote>

<p>Amen!</p>

<h2><a href="http://sixtwothree.org/posts/in-defense-of-progressive-enhancement">In Defense of Progressive Enhancement</a></h2>

<p>In his follow-up, Jason defends his position against <a href="http://viget.com/inspire/designing-experience-layers#comment-1847156038">a lengthy comment from his supervisor at Viget</a>. Jason’s responses are dead on:</p>

<ol>
<li>JavaScript is not a baseline (or a given) and</li>
<li>When large sites put their eggs in the JS basket, they set a bad example for other developers.</li>
</ol>


<p>His summation is perfect:</p>

<blockquote><p>I remain unconvinced that abandoning progressive enhancement in favor of JavaScript-first development is better for users or is the direction the Web is inevitably heading. It’s our responsibility to do right by the billions already online and the next billion preparing to come online. We can achieve this by designing robust, resilient, layered experiences using techniques like progressive enhancement.</p></blockquote>

<p>Again, fantastic.</p>

<h2><a href="http://sixtwothree.org/posts/the-practical-case-for-progressive-enhancement">The Practical Case for Progressive Enhancement</a></h2>

<p>Continuing the thread, Jason assembles more reasons to adopt the progressive enhancement philosophy.</p>

<ol>
<li><strong>The “Moral” Argument for Progressive Enhancement</strong> &ndash; Personally, I think Jason gives in too easily on this. Access to content is <a href="http://www.pewinternet.org/topics/digital-divide/">a social justice issue</a> and that is nothing to gloss over. In some cases it is also a <a href="http://www.section508.gov/">legal requirement</a>.</li>
<li><strong>The “Cost” of Progressive Enhancement</strong> &ndash; Jason does a good job addressing the costs (monetarily and temporally) associated with adopting progressive enhancement in terms of building, testing, and supporting websites. As he says, it is more costly to &ldquo;bolt on&rdquo; accessibility and progressive enhancement at the end of a project. He is also correct in his assertion that progressively-enhanced websites actually require less testing. And when you <a href="http://bradfrost.com/blog/mobile/support-vs-optimization/">draw a stark line between support and optimization</a>, support for additional browsers and devices also becomes far less costly. What Jason was missing was numbers to back all this up. <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement/">I have those numbers</a>. Enjoy.</li>
<li><strong>Practicality</strong> &ndash; Finally, Jason calls out games and their ilk as edge cases. He correctly asserts that the vast majority of properties on the Web could easily be built following progressive enhancement. Sure, you might not build a Photoshop clone using progressive enhancement, but how many of you are building an image editor for the Web? I didn’t think so.</li>
</ol>


<h2>Conclusion</h2>

<p>In all, this was a nice little series. Great work Jason! If you want to dig into this progressive enhancement stuff a bit more, you can read the entirety of my award-winning book <a href="http://adaptivewebdesign.info/1st-edition/"><cite>Adaptive Web Design: Crafting Rich Experiences with Progressive Enhancement</cite> online, for free</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The One Weird Trick That Takes the Pain Out of Cross-browser Testing]]></title>
    <link href="http://aaron-gustafson.com/notebook/the-one-weird-trick-that-takes-the-pain-out-of-cross-browser-testing/"/>
    <updated>2015-01-26T11:24:25-05:00</updated>
    <id>http://aaron-gustafson.com/notebook/the-one-weird-trick-that-takes-the-pain-out-of-cross-browser-testing</id>
    <content type="html"><![CDATA[<p>Love this!</p>

<p>{% tweet <a href="https://twitter.com/decadecity/status/559693419808034816">https://twitter.com/decadecity/status/559693419808034816</a> %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adaptive Images in ExpressionEngine With CE Image]]></title>
    <link href="http://aaron-gustafson.com/notebook/adaptive-images-in-expressionengine-with-ce-image/"/>
    <updated>2014-11-21T18:18:23-05:00</updated>
    <id>http://aaron-gustafson.com/notebook/adaptive-images-in-expressionengine-with-ce-image</id>
    <content type="html"><![CDATA[<p>One of the biggest headaches of responsive design has been dealing with images. Thankfully our work on the <a href="http://ricg.io">Responsive <del>Images</del> <ins>Issues</ins> Community Group</a> has resulted in a rock-solid set of elements and attributes to address all of your adaptive image needs. My company, <a href="http://easy-designs.net">Easy Designs</a>, recently redesigned <a href="http://www.nichols.edu">Nichols College’s website</a> and that project just happened to coincide adaptive images landing in <a href="http://www.chromium.org/blink">Blink</a> (the rendering engine that powers Chrome and Opera). Naturally, we jumped at the opportunity to use them.</p>

<!-- more -->


<p>Most Nichols College sites run on <a href="http://ellislabs.com/expressionengine">EllisLab’s ExpressionEngine</a>, a solid little workhorse of a CMS we’ve been using for years. We love it because it gives us complete control over the markup it generates. Now EE offers some pretty decent file management and image manipulation utilities out of the box, but the options it provides were not enough to handle our adaptive image needs; we needed backup. <a href="http://www.causingeffect.com/software/expressionengine/ce-image">Causing Effect’s CE Image</a> add-on is reasonably priced and offered exactly the functionality we needed to make our adaptive image dreams a reality.</p>

<p>I won’t bore you with how to set up CE Image as there is <a href="http://www.causingeffect.com/software/expressionengine/ce-image/user-guide">documentation on that</a>, but I will walk you through two different responsive image use-cases we had and how we addressed them using this add-on.</p>

<h2>Header images</h2>

<p>The first use case we had was a series of large, focal images. You can find different examples of them on <a href="http://www.nichols.edu">the homepage</a> and landing pages (like <a href="http://www.nichols.edu/admissions/">this one for Admissions</a>). The first pass on making these images adaptive involved the <code>picture</code> element for which <a href="https://html.spec.whatwg.org/multipage/embedded-content.html#adaptive-images">the spec</a> is known. The markup we were generating was based on the pattern outlined for <a href="http://scottjehl.github.io/picturefill/">Picturefill</a>, a JavaScript polyfill that implements adaptive images in browsers that don’t do it natively:</p>

<p>{% gist 96dd157a0206d59ac30a picture-result.html %}</p>

<p>To get to that point, however, we needed to use CE Image to generate (and cache) the specific sizes we needed:</p>

<p>{% gist 96dd157a0206d59ac30a picture-element.html %}</p>

<p>Not what’s a lot of code, so let’s just look at one segment of that jumble:</p>

<p>{% gist 96dd157a0206d59ac30a  picture-excerpt.html %}</p>

<p>This is an example using CE Image’s tag pair option, which lets you control the markup output. In the opening tag, we set several properties:</p>

<ul>
<li><code>src</code> is the path to the original image uploaded by content authors;</li>
<li><code>filename_suffix</code> is the suffix we want added to the cached file to differentiate it from others in the cache (and make the files more easily scannable);</li>
<li><code>width</code> is our desired output width for the generated image;</li>
<li><code>allow_scale_larger</code> does exactly what you’d expect: it dictates whether or not CE Image should scale the image to reach the desired width;</li>
<li><code>crop</code> tells CE Image whether it’s okay to crop the image;</li>
<li><code>interlace</code> tells CE Image to use image interlacing (which can speed load time); and</li>
<li><code>cache_dir</code> tells CE Image where to store the cached image (in relation to our global configuration)</li>
</ul>


<p>Then, within the tag pair is the <code>source</code> element with the <code>srcset</code> value set to the path to the file CE Image generated (referenced by the <code>made</code> variable) and the associated media query.</p>

<p>Multiply that a few times for the different sizes and you have the full <code>picture</code> element.</p>

<p>Now that’s all well and good, but shortly after launch, <a href="http://ericportis.com/">Eric Portis</a> wrote <a href="http://ericportis.com/posts/2014/srcset-sizes/">an amazing post explaining how the <code>srcset</code> and <code>sizes</code> attributes operate</a> and it cleared up a lot of my confusion on the matter. He convinced me that the age-old <code>img</code> element, with these new attributes, would be far more maintainable. With a fire in my belly, I rewrote the markup:</p>

<p>{% gist 96dd157a0206d59ac30a  simple-resize.html %}</p>

<p>The CE Image behavior is exactly the same, but the resulting markup is much clearer:</p>

<p>{% gist 96dd157a0206d59ac30a  srcset-result.html %}</p>

<p>The added bonus of this approach is that I am not hard-coding any media queries and the browser gets to make the ultimate decision of which image to request. All I am doing is telling the browser the image options and their respective widths within the <code>srcset</code> attribute. As all of the images take up 100% of their containers, I didn’t even need to use the <code>sizes</code> attribute. Easy peasy.</p>

<h2>&ldquo;Nice to Have&rdquo; Images</h2>

<p>Not every image adds something to the page. Some are purely optional, a visual enhancement. In order to reduce the size of pages on smaller screens, we often choose to &ldquo;lazy load&rdquo; certain image assets after page load, when we know there is enough room to display the image or when we feel it would be an enhancement to the design.</p>

<p>Now some of you might be wondering: <em>Why not just <code>display:none</code> below a certain threshold?</em> Well, I’ll tell you: images that are hidden with CSS are still requested by the browser. That means users who don’t see the images are still paying to download them (whether in terms of time waiting for the page to render or actual money on a metered connection). That kinda sucks for them. We should show our users a bit more respect and only request the images when we need them.</p>

<p>We wrote <a href="https://github.com/easy-designs/easy-lazy-images.js">a lazy-loading image script</a> a few years back and have battle tested it on numerous sites to great success. It’s all based on a simple markup pattern:</p>

<p>{% gist 96dd157a0206d59ac30a lazy-loaded-markup.html %}</p>

<p>The <code>data-img-src</code> attribute defines the path to the &ldquo;nice to have&rdquo; image and then the JavaScript adds the image element into the page when the appropriate conditions are met:</p>

<p>{% gist 96dd157a0206d59ac30a lazy-loaded-result.html %}</p>

<p>Pretty simple. It even supports <code>srcset</code>:</p>

<p>{% gist 96dd157a0206d59ac30a lazy-loaded-srcset.html %}</p>

<p>The <a href="https://github.com/easy-designs/easy-lazy-images.js#usage">full documentation is up on Github</a>.</p>

<p>Implementing this in the context of CE Image was a breeze and builds on the <code>source</code> pattern I showed earlier:</p>

<p>{% gist 96dd157a0206d59ac30a lazy-loading.html %}</p>

<p>We are only just beginning to scratch the surface of what’s possible with adaptive images and I am sure we will come up with newer, better ways to do this stuff. Heck, there may even be an adaptive images add-on in the pipeline for ExpressionEngine. But, in the meantime, if you are trying to implement adaptive images with ExpressionEngine, CE Image is a good way to go.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Embraces Progressive Enhancement]]></title>
    <link href="http://aaron-gustafson.com/notebook/google-embraces-progressive-enhancement/"/>
    <updated>2014-10-28T21:07:35-04:00</updated>
    <id>http://aaron-gustafson.com/notebook/google-embraces-progressive-enhancement</id>
    <content type="html"><![CDATA[<p>In case you missed it, <a href="http://googlewebmastercentral.blogspot.com/2014/10/updating-our-technical-webmaster.html">yesterday Pierre Far updated Google’s Webmaster Guidelines</a>. In his post, Pierre lays out their case for <a href="https://en.wikipedia.org/wiki/Progressive_enhancement">progressive enhancement</a>:</p>

<blockquote><p>Just like modern browsers, our rendering engine might not support all of the technologies a page uses. Make sure your web design adheres to the principles of progressive enhancement as this helps our systems (and a wider range of browsers) see usable content and basic functionality when certain web design features are not yet supported.</p></blockquote>

<!-- more -->


<p>As someone who has been beating the drum for progressive enhancement for over a decade, this sort of support from such an influential company gets me a little teary-eyed.</p>

<p>It’s nice to see Steve Champeon’s philosophy for web design finally beginning to gain traction outside of the ivory tower of Web standards. It is a fantastic philosophy that has been guiding our work since Steve unveiled it. And it has paid some handsome dividends for both us and our clients.</p>

<p>If you need help wrapping your head around progressive enhancement, you should read <a href="#fn-2014-10-28">my introductory series for <cite>A List Apart</cite></a>. If you want more, there’s also <a href="http://adaptivewebdesign.info">my book on progressive enhancement: <cite>Adaptive Web Design</cite></a>. And if you need help getting your team up to speed, I’m more than happy to hop on a plane and come to you. Just <a href="/contact/">drop me a line</a>. I have helped many companies embrace this philosophy and have seen it improve their productivity, increase their reach by supporting more devices, and improve the accessibility of their products. Oh… and <a href="http://blog.easy-designs.net/archives/the-true-cost-of-progressive-enhancement">progressive enhancement has saved our clients real money and reduced their time to market</a>.</p>

<p>I don’t tend to be a “magic pill” kind of believer, but I can honestly say that embracing progressive enhancement can radically change your business for the better. And I’m glad to see Google agrees with me.</p>

<h2 id="fn-2014-10-28">My (still-relevant) 2008 series on Progressive Enhancement</h2>


<ol>
<li><a href="http://www.alistapart.com/articles/understandingprogressiveenhancement/">Understanding Progressive Enhancement</a></li>
<li><a href="http://www.alistapart.com/articles/progressiveenhancementwithcss/">Progressive Enhancement with CSS</a></li>
<li><a href="http://www.alistapart.com/articles/progressiveenhancementwithjavascript/">Progressive Enhancement with JavaScript</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
